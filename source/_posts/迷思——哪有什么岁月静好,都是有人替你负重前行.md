---
title: 迷思——哪有什么岁月静好,都是有人替你负重前行
abbrlink: 4d82216e
date: 2025-08-21 01:36:58
tags:
categories:
cover:
description:
swiper_index:
sticky:
---

起因是, 笔者想要在Unity中实现一些基于UGUI的拖拽效果, 于是开始去思考UGUI是如何实现响应输入的, 接着了解到Unity的EventSystem和一系列EventHandler接口(IPointerClickHandler、 IDragHandler等)来驱动整个System的运转. 笔者在这篇博客中并非是要讨论EventSystem的具体实现. 而是想陈述自己对EventHandler这些接口在UGUI体系中扮演角色的一些迷思. 作为UGUI的使用者, 我只关心如何实现自己想要的功能. 如果我想让一个UI元素可以响应点击, 那我就要创建一个继承自MonoBehaviour的脚本, 挂载到这个UI元素上, 并且还要实现IPointerClickHandler接口, 这样就结束了, 至于怎么样在运行时获取到这个UI元素上的脚本实例, 以及如何触发接口中的方法, 我不关心, Unity会帮我处理. 这就是我对接口最初的理解, **我**只负责接口行为的定义, 我不负责接口行为的调用. 于是有一段时间我经常会遇到这种处境: 在业务的开发中发现一些类型中能抽象出一部分行为封装成接口, 但有可能这些类根本就不是同一个概念下的东西, 或者, 正是由于这种 只考考虑抽离行为 而不考虑接口调用时机和接口持有者的数据组织格式, 导致绝大部分抽离行为封装接口的操作都十分多余. 

接口的行为不止于此 我记得在刚入行的时候, 一个程序员前辈跟我说, 写代码是一个十分繁琐的过程, 但如果你觉得某一部分代码写起来好像不用那么繁琐就能实现你的功能, 那有可能是有人在你不知道的地方帮你做了很多事情. 我上面举的EventSystem就是这样一个例子, UGUI系统通过对外暴露EventHandler接口的方式, 在内部有能够持有接口实例的方法, 你不需要去关心UGUI系统内部是如何持有接口示例的. YooAsset自定义打包Step也是类似的思想, 二者都是通过某种方式持有了外部的对象实例, Unity是通过运行时持有并遍历所有的GameObject, 找到上面的EventHandler来持有它们, 而YooAsset则是在Init时将需要的buildstep实例注册到YooAsset内部去. 两者的思想或许可以表述如下: **外部定义行为, 内部控制流程**.

最近笔者想要给项目的换皮活动也做一个类似的, 一个活动换皮要有下面几个固定的步骤 导入资源、更新配置表, 定义一个IStep接口, 接口内有一个Action行为, 调用方可以实现多个继承IStep接口的类, 比如导入资源类、更新配置表类, 然后在Action行为中就可以实现是如何导入资源的、如何更新配置表的. 然后将导入资源类和更新配置表类再注册到一个序列化的数据结构或者硬编码的脚本中, 在执行换皮的时候就是从序列化数据或者硬编码脚本中拿到这一套流程信息 传入到 我这套换皮框架中, 外部不用管我内部是如何驱动这套流程信息运转的, 这样的模式和上面举的UGUI、YooAsset的例子大同小异.

Unity协程、C#的Task也是如此, 只因我被“保护”得太好了, Unity的协程和Task都很好用, 丢进去一个异步的任务, 让他自己在那里执行就好了, 可是异步任务本质上是怎么执行的呢? Unity协程依赖于MonoBehaviour的Update机制, Task依赖于C#内部的线程池. 背后都会有一个间隔一定时间轮询的逻辑, 只是我不需要关心这段逻辑罢了

我有段时间看了大量讲述C#Task的文章, 现在再去回想其实还是不甚理解, 多去想想

定义接口的目的, 让一些类型具有某些行为, 并且可以通过声明接口类型, 来持有接口的实例, 一个实例的对象既可以是该实例的class类型, 也可以是其实现的任意一个接口的类型.
下面列举了笔者在开发过程中遇到的

1. C#中的非托管资源在使用的时候可以实现IDisposable接口, 在Dispose接口中, 给了开发者比较统一便捷的方式对不同的非托管资源进行释放的一个点, 另外其中


3. 语法糖foreach, 有一个IEnumerable和IEnumerator, 使用IEnumerable标识一个类型的身份, 

因此 接口在设计隔离性、统一操作、标识统一身份等场景下能发挥作用. 

# 对IMGUI和UGUI实现机制的思考

正如上面所说
IMGUI既要操心交互逻辑是什么, 还要在OnGUI方法里自己去写UI组件触发的检测逻辑.

UGUI则只需要操心交互的逻辑是什么, 不需要操心如何做检测的.

但是从实现方案上看, IMGUI这套完全可以用UGUI那一套的思想, UGUI用了一套EventSystem作为 触发交互的检测逻辑放在同一个地方集中处理. UGUI使用的输入的封装是`Input`, 将Input中得到的屏幕输入信息传递给`EventSystem`, 通过Raycaster模块得到 Input中的屏幕输入位置得到射线触碰到了哪个物体`GameObject`, 然后去获取到这个物体上面所有UGUI体系中的EventHandler, 根据Input中传来的触碰信息(按下、拖拽等)去触发相关的Handler, 如果这个GameObject上有相关的组件的话.

IMGUI这一套的UI组件不是以组件的方式组织的, 是以`Rect`为结构组织的, IMGUI使用的输入的封装是`Event`, IMGUI这一套, 不是通过什么按钮组件之类的去判断的, 所有的组件都是一个Rect, 对外暴露方法, 比如Button或者Toggle, 然后在OnGUI中 就相当于Update方法, 去查询所有的Rect区域, 首先判断一下鼠标在不在这个区域里面, 如果这个区域你是作为按钮去使用的, 那么继续去看`Event`中`EventType`字段表示鼠标是不是按下了, 如果按下了, 则返回True, 那么在OnGUI的逻辑里面就拿到了返回值是true, 代表这个按钮被按下了, 就可以去执行按钮点击的逻辑了. 去判断当前鼠标的位置, 以及鼠标的状态 比如是点击、持续点击、拖拽等等, 然后直接在这个方法内, 根据数据的数据做对应的逻辑和表现. 


UGUI机制剖析 

